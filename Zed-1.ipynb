{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyzed.sl as sl\n",
    "\n",
    "# importing required libraries\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import QtWidgets, uic\n",
    "from PyQt5.QtMultimedia import *\n",
    "from PyQt5.QtMultimediaWidgets import *\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! No module named 'sounddevice'\n",
      "Warning! No module named 'matplotlib'\n",
      "Warning! No module named 'keras'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# https://github.com/citrusvanilla/horizon_detection\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Form implementation generated from reading ui file 'process.ui'\n",
    "#\n",
    "# Created by: PyQt5 UI code generator 5.11.3\n",
    "#\n",
    "# WARNING! All changes made in this file will be lost!\n",
    "#\n",
    "# Subscribe to PyShine Youtube channel for more detail! \n",
    "\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import QFileDialog\n",
    "from PyQt5.QtGui import QImage\n",
    "import cv2, imutils\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import pyzed.sl as sl\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyshine as ps\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "try:\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "except Exception as e:\n",
    "    print('Warning...',e)\n",
    "\n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        # MainWindow.resize(1024, 720)\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setMinimumSize(1024, 720)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        self.gridLayout_2 = QtWidgets.QGridLayout(self.centralwidget)\n",
    "        self.gridLayout_2.setObjectName(\"gridLayout_2\")\n",
    "        self.horizontalLayout = QtWidgets.QHBoxLayout()\n",
    "        self.horizontalLayout.setObjectName(\"horizontalLayout\")\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label.setText(\"\")\n",
    "        # self.label.setPixmap(QtGui.QPixmap(\"images/H.png\"))\n",
    "        self.label.setObjectName(\"label\")\n",
    "        self.horizontalLayout.addWidget(self.label)\n",
    "        self.gridLayout = QtWidgets.QGridLayout()\n",
    "        self.gridLayout.setObjectName(\"gridLayout\")\n",
    "        # self.verticalSlider = QtWidgets.QSlider(self.centralwidget)\n",
    "        # self.verticalSlider.setOrientation(QtCore.Qt.Vertical)\n",
    "        # self.verticalSlider.setObjectName(\"verticalSlider\")\n",
    "        # self.gridLayout.addWidget(self.verticalSlider, 0, 0, 1, 1)\n",
    "        # self.verticalSlider_2 = QtWidgets.QSlider(self.centralwidget)\n",
    "        # self.verticalSlider_2.setOrientation(QtCore.Qt.Vertical)\n",
    "        # self.verticalSlider_2.setObjectName(\"verticalSlider_2\")\n",
    "        # self.gridLayout.addWidget(self.verticalSlider_2, 0, 1, 1, 1)\n",
    "        self.label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label_2.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.label_2.setObjectName(\"label_2\")\n",
    "        self.gridLayout.addWidget(self.label_2, 1, 0, 1, 1)\n",
    "        # self.label_3 = QtWidgets.QLabel(self.centralwidget)\n",
    "        # self.label_3.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        # self.label_3.setObjectName(\"label_3\")\n",
    "        # self.gridLayout.addWidget(self.label_3, 1, 1, 1, 1)\n",
    "        self.horizontalLayout.addLayout(self.gridLayout)\n",
    "        self.gridLayout_2.addLayout(self.horizontalLayout, 0, 0, 1, 2)\n",
    "        self.horizontalLayout_2 = QtWidgets.QHBoxLayout()\n",
    "        self.horizontalLayout_2.setObjectName(\"horizontalLayout_2\")\n",
    "        # self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        # self.pushButton.setObjectName(\"pushButton\")\n",
    "        # self.horizontalLayout_2.addWidget(self.pushButton)\n",
    "        self.pushButton_2 = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton_2.setObjectName(\"pushButton_2\")\n",
    "        self.horizontalLayout_2.addWidget(self.pushButton_2)\n",
    "        self.gridLayout_2.addLayout(self.horizontalLayout_2, 1, 0, 1, 1)\n",
    "        spacerItem = QtWidgets.QSpacerItem(313, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum)\n",
    "        self.gridLayout_2.addItem(spacerItem, 1, 1, 1, 1)\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        # self.verticalSlider.valueChanged['int'].connect(self.brightness_value)\n",
    "        # self.verticalSlider_2.valueChanged['int'].connect(self.blur_value)\n",
    "        self.pushButton_2.clicked.connect(self.loadImage)\n",
    "        # self.pushButton.clicked.connect(self.savePhoto)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "        \n",
    "        # Added code here\n",
    "        self.filename = 'Snapshot '+str(time.strftime(\"%Y-%b-%d at %H.%M.%S %p\"))+'.png' # Will hold the image address location\n",
    "        self.tmp = None # Will hold the temporary image for display\n",
    "        self.brightness_value_now = 0 # Updated brightness value\n",
    "        self.blur_value_now = 0 # Updated blur value\n",
    "        self.fps=0\n",
    "        self.started = False\n",
    "\n",
    "    def loadImage(self):\n",
    "        \"\"\" This function will load the camera device, obtain the image\n",
    "            and set it to label using the setPhoto function\n",
    "        \"\"\"\n",
    "        if self.started:\n",
    "            self.started=False\n",
    "            self.pushButton_2.setText('Start')\t\n",
    "        else:\n",
    "            self.started=True\n",
    "            self.pushButton_2.setText('Stop')\n",
    "        \n",
    "        cam = True # True for webcam\n",
    "        # Create a ZED camera object\n",
    "        zed = sl.Camera()\n",
    "        # if cam:\n",
    "        vid = cv2.VideoCapture(1)\n",
    "        \n",
    "\n",
    "        # Set configuration parameters\n",
    "        # input_type = sl.InputType()\n",
    "        # if len(sys.argv) >= 2 :\n",
    "        #     input_type.set_from_svo_file(sys.argv[1])\n",
    "        # init = sl.InitParameters(input_t=input_type)\n",
    "        init = sl.InitParameters()\n",
    "        # init.camera_resolution = sl.RESOLUTION.HD1080\n",
    "        init.camera_fps = 30\n",
    "\n",
    "        init.camera_resolution = sl.RESOLUTION.HD1080\n",
    "        init.depth_mode = sl.DEPTH_MODE.PERFORMANCE\n",
    "        init.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "        # Open the camera\n",
    "        err = zed.open(init)\n",
    "        if err != sl.ERROR_CODE.SUCCESS :\n",
    "            print(repr(err))\n",
    "            zed.close()\n",
    "            exit(1)\n",
    "\n",
    "        self.image = sl.Mat()\n",
    "        runtime = sl.RuntimeParameters()\n",
    "        runtime.sensing_mode = sl.SENSING_MODE.STANDARD\n",
    "\n",
    "        # Prepare new image size to retrieve half-resolution images\n",
    "        image_size = zed.get_camera_information().camera_resolution\n",
    "        image_size.width = image_size.width /2\n",
    "        image_size.height = image_size.height /2\n",
    "\n",
    "        # Declare your sl.Mat matrices\n",
    "        image_zed = sl.Mat(image_size.width, image_size.height, sl.MAT_TYPE.U8_C4)\n",
    "        depth_image_zed = sl.Mat(image_size.width, image_size.height, sl.MAT_TYPE.U8_C4)\n",
    "        point_cloud = sl.Mat()\n",
    "\n",
    "        key = ' '\n",
    "\n",
    "        # else:\n",
    "        #     vid = cv2.VideoCapture('video.mp4')\n",
    "        \n",
    "        cnt=0\n",
    "        frames_to_count=20\n",
    "        st = 0\n",
    "        fps=0\n",
    "\n",
    "        sensors_data = sl.SensorsData()\n",
    "        self.compasshead = 0\n",
    "        heading_list = []\n",
    "        # magnetometer_data = sl.SensorsData.get_magnetometer_data()\n",
    "        \n",
    "        # while(vid.isOpened()):\n",
    "        while(zed.grab(runtime) == sl.ERROR_CODE.SUCCESS and key != 113):\n",
    "            QtWidgets.QApplication.processEvents()\n",
    "\n",
    "            # Retrieve the left image, depth image in the half-resolution\n",
    "            zed.retrieve_image(image_zed, sl.VIEW.LEFT, sl.MEM.CPU, image_size)\n",
    "            zed.retrieve_image(depth_image_zed, sl.VIEW.DEPTH, sl.MEM.CPU, image_size)\n",
    "            # Retrieve the RGBA point cloud in half resolution\n",
    "            zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA, sl.MEM.CPU, image_size)\n",
    "\n",
    "            # To recover data from sl.Mat to use it with opencv, use the get_data() method\n",
    "            # It returns a numpy array that can be used as a matrix with opencv\n",
    "            image_ocv = image_zed.get_data()\n",
    "            depth_image_ocv = depth_image_zed.get_data()\n",
    "\n",
    "            # cv2.imshow(\"Image\", image_ocv)\n",
    "            # cv2.imshow(\"Depth\", depth_image_ocv)\n",
    "            self.image = image_ocv\n",
    "\n",
    "            zed.get_sensors_data(sensors_data, sl.TIME_REFERENCE.IMAGE) # Retrieve only frame synchronized data\n",
    "\n",
    "            # Extract magnetometer data\n",
    "            magnetometer_data = sensors_data.get_magnetometer_data()\n",
    "\n",
    "            # # Retrieve uncalibrated magnetic field\n",
    "            # self.magnetic_field = magnetometer_data.get_magnetic_field_uncalibrated();  \n",
    "            # print(self.magnetic_field)\n",
    "            \n",
    "            # Retrieve calibrated magnetic field\n",
    "            magnetic_field = magnetometer_data.get_magnetic_field_calibrated();\n",
    "            # print(magnetometer_data.magnetic_heading_state)\n",
    "            # print(magnetometer_data.magnetic_heading_accuracy)\n",
    "            heading = round(magnetometer_data.magnetic_heading)\n",
    "            if(heading < 0):\n",
    "                heading = 360 + heading\n",
    "            # if(abs(self.compasshead - heading) > 5):\n",
    "            # heading_list.append(heading)\n",
    "            #     print(heading_list)\n",
    "            self.compasshead = heading\n",
    "            # if(len(heading_list) >= 10):\n",
    "            #     result = savgol_filter(heading_list, 10, 5) # window size 13, polynomial order 5\n",
    "            #     heading_list.pop(0)\n",
    "            #     # heading_list.pop(4)\n",
    "            #     self.compasshead = round(result[5])\n",
    "            #     # heading_list.append(self.compasshead)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY) \n",
    "            try:\n",
    "                faces = faceCascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.15,  \n",
    "                minNeighbors=7, \n",
    "                minSize=(80, 80), \n",
    "                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "                \n",
    "                for (x, y, w, h) in faces:\n",
    "                    cv2.rectangle(self.image, (x, y), (x + w, y + h), (10, 228,220), 5) \n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "            if cnt == frames_to_count:\n",
    "                try: # To avoid divide by 0 we put it in try except\n",
    "                    # print(frames_to_count/(time.time()-st),'FPS') \n",
    "                    self.fps = round(frames_to_count/(time.time()-st)) \n",
    "                    \n",
    "                    \n",
    "                    st = time.time()\n",
    "                    cnt=0\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            cnt+=1\n",
    "            \n",
    "            self.update()\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if self.started==False:\n",
    "                zed.close()\n",
    "                break\n",
    "                print('Loop break')\n",
    "\n",
    "    def setPhoto(self,image):\n",
    "        \"\"\" This function will take image input and resize it \n",
    "            only for display purpose and convert it to QImage\n",
    "            to set at the label.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "\n",
    "        img_overlay_rgba = np.array(Image.open(\"compass-scale.png\"))\n",
    "        compass_arrow = np.array(Image.open(\"compass_arrow.png\"))\n",
    "\n",
    "        compass_arrow = imutils.resize(compass_arrow, height=50)\n",
    "\n",
    "        aspect = self.centralwidget.frameGeometry().width() / self.centralwidget.frameGeometry().height()\n",
    "        if (aspect <= 16/9):\n",
    "            \n",
    "            image = imutils.resize(image, width=self.centralwidget.frameGeometry().width())\n",
    "            img_overlay_rgba = imutils.resize(img_overlay_rgba, width=self.centralwidget.frameGeometry().width())\n",
    "        else:\n",
    "            \n",
    "            image = imutils.resize(image, height=self.centralwidget.frameGeometry().height())\n",
    "            img_overlay_rgba = imutils.resize(img_overlay_rgba, height=self.centralwidget.frameGeometry().height())\n",
    "\n",
    "\n",
    "        x = round((image.shape[1]-img_overlay_rgba.shape[1])/2)\n",
    "        y = round((image.shape[0]-img_overlay_rgba.shape[0])/2)\n",
    "        if y<0:\n",
    "            y = 0\n",
    "        y = round(y + image.shape[0] - 300)\n",
    "        # instead of using immediate rotate, use a function to iterate the value based on the delta.\n",
    "        img_overlay_rgba = imutils.rotate(img_overlay_rgba, self.compasshead)\n",
    "\n",
    "        # Perform blending\n",
    "        alpha_mask = img_overlay_rgba[:, :, 3] / 255.0\n",
    "        img_result = image[:, :, :3].copy()\n",
    "        img_overlay = img_overlay_rgba[:, :, :3]\n",
    "\n",
    "        self.overlay_image_alpha(img_result, img_overlay, x, y, alpha_mask)\n",
    "        image = img_result\n",
    "\n",
    "\n",
    "        x = round((image.shape[1]-compass_arrow.shape[1])/2)\n",
    "        y = image.shape[0] - 80\n",
    "        # # print(yoff,xoff)\n",
    "\n",
    "        # # use numpy indexing to place the resized image in the center of background image\n",
    "        # result = image.copy()\n",
    "        # result[y:y+compass_arrow.shape[1], x:x+compass_arrow.shape[0]] = compass_arrow\n",
    "        # image = result\n",
    "\n",
    "        # Perform blending\n",
    "        alpha_mask = compass_arrow[:, :, 3] / 255.0\n",
    "        img_result = image[:, :, :3].copy()\n",
    "        img_overlay = compass_arrow[:, :, :3]\n",
    "\n",
    "        self.overlay_image_alpha(img_result, img_overlay, x, y, alpha_mask)\n",
    "        image = img_result\n",
    "\n",
    "        frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = QImage(frame, frame.shape[1],frame.shape[0],frame.strides[0],QImage.Format_RGB888)\n",
    "        self.label.setPixmap(QtGui.QPixmap.fromImage(image))\n",
    "        \n",
    "    def overlay_image_alpha(self,img, img_overlay, x, y, alpha_mask):\n",
    "        \"\"\"Overlay `img_overlay` onto `img` at (x, y) and blend using `alpha_mask`.\n",
    "\n",
    "        `alpha_mask` must have same HxW as `img_overlay` and values in range [0, 1].\n",
    "        \"\"\"\n",
    "        # Image ranges\n",
    "        y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n",
    "        x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n",
    "\n",
    "        # Overlay ranges\n",
    "        y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n",
    "        x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n",
    "\n",
    "        # Exit if nothing to do\n",
    "        if y1 >= y2 or x1 >= x2 or y1o >= y2o or x1o >= x2o:\n",
    "            return\n",
    "\n",
    "        # Blend overlay within the determined ranges\n",
    "        img_crop = img[y1:y2, x1:x2]\n",
    "        img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n",
    "        alpha = alpha_mask[y1o:y2o, x1o:x2o, np.newaxis]\n",
    "        alpha_inv = 1.0 - alpha\n",
    "\n",
    "        img_crop[:] = alpha * img_overlay_crop + alpha_inv * img_crop\n",
    "\n",
    "    def brightness_value(self,value):\n",
    "        \"\"\" This function will take value from the slider\n",
    "            for the brightness from 0 to 99\n",
    "        \"\"\"\n",
    "        self.brightness_value_now = value\n",
    "        # print('Brightness: ',value)\n",
    "        self.update()\n",
    "        \n",
    "        \n",
    "    def blur_value(self,value):\n",
    "        \"\"\" This function will take value from the slider \n",
    "            for the blur from 0 to 99 \"\"\"\n",
    "        self.blur_value_now = value\n",
    "        print('Blur: ',value)\n",
    "        self.update()\n",
    "\n",
    "\n",
    "    def changeBrightness(self,img,value):\n",
    "        \"\"\" This function will take an image (img) and the brightness\n",
    "            value. It will perform the brightness change using OpenCv\n",
    "            and after split, will merge the img and return it.\n",
    "        \"\"\"\n",
    "        hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "        h,s,v = cv2.split(hsv)\n",
    "        lim = 255 - value\n",
    "        v[v>lim] = 255\n",
    "        v[v<=lim] += value\n",
    "        final_hsv = cv2.merge((h,s,v))\n",
    "        img = cv2.cvtColor(final_hsv,cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "        \n",
    "    def changeBlur(self,img,value):\n",
    "        \"\"\" This function will take the img image and blur values as inputs.\n",
    "            After perform blur operation using opencv function, it returns \n",
    "            the image img.\n",
    "        \"\"\"\n",
    "        kernel_size = (value+1,value+1) # +1 is to avoid 0\n",
    "        img = cv2.blur(img,kernel_size)\n",
    "        return img\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\" This function will update the photo according to the \n",
    "            current values of blur and brightness and set it to photo label.\n",
    "        \"\"\"\n",
    "        img = self.changeBrightness(self.image,self.brightness_value_now)\n",
    "        # img = self.changeBlur(img,self.blur_value_now)\n",
    "\n",
    "\n",
    "        # Here we add display text to the image\n",
    "        # text  =  'FPS: '+str(self.fps)\n",
    "        # img = ps.putBText(img,text,text_offset_x=20,text_offset_y=30,vspace=20,hspace=10, font_scale=1.0,background_RGB=(10,20,222),text_RGB=(255,255,255))\n",
    "        text = str(self.compasshead)\n",
    "        img = ps.putBText(img,text,text_offset_x=int(self.image.shape[1]/2),text_offset_y=30,vspace=20,hspace=10, font_scale=1.0,background_RGB=(228,20,222),text_RGB=(255,255,255))\n",
    "        # text  =  f\"Brightness: {self.brightness_value_now}\"\n",
    "        # img = ps.putBText(img,text,text_offset_x=80,text_offset_y=425,vspace=20,hspace=10, font_scale=1.0,background_RGB=(20,210,4),text_RGB=(255,255,255))\n",
    "        # text  =  f'Blur: {self.blur_value_now}: '\n",
    "        # img = ps.putBText(img,text,text_offset_x=self.image.shape[1]-200,text_offset_y=425,vspace=20,hspace=10, font_scale=1.0,background_RGB=(210,20,4),text_RGB=(255,255,255))\n",
    "\n",
    "\n",
    "        self.setPhoto(img)\n",
    "\n",
    "    def savePhoto(self):\n",
    "        \"\"\" This function will save the image\"\"\"\n",
    "        self.filename = 'Snapshot '+str(time.strftime(\"%Y-%b-%d at %H.%M.%S %p\"))+'.png'\n",
    "        cv2.imwrite(self.filename,self.tmp)\n",
    "        print('Image saved as:',self.filename)\n",
    "\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"Zed Navigation\"))\n",
    "        self.pushButton_2.setText(_translate(\"MainWindow\", \"Start\"))\n",
    "        # self.label_2.setText(_translate(\"MainWindow\", \"Brightness\"))\n",
    "        # self.label_3.setText(_translate(\"MainWindow\", \"Blur\"))\n",
    "        # self.pushButton.setText(_translate(\"MainWindow\", \"Take picture\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\timport sys\n",
    "\tapp = QtWidgets.QApplication(sys.argv)\n",
    "\tMainWindow = QtWidgets.QMainWindow()\n",
    "\tui = Ui_MainWindow()\n",
    "\tui.setupUi(MainWindow)\n",
    "\tMainWindow.show()\n",
    "\tsys.exit(app.exec_())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95cdb06e919eab5e2c554174537356ac9b55200d1eb6f880dc25de04343a18ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
